{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJhMOTUODvZtexm57P/hwK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Artificial-Intelligence-workshop/blob/main/7.a.%20Naive%20Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "ğŸ“Œ Ù†Ø§ÙŠÙˆ Ø¨ÛŒØ² (Naive Bayes) ÛŒØ¹Ù†ÛŒ Ú†ÛŒØŸ\n",
        "\n",
        "ØªØµÙˆØ± Ú©Ù† Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¨ÙÙ‡Ù…ÛŒ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ø§Ø³Ù¾Ù… Ù‡Ø³Øª ÛŒØ§ Ù†Ù‡.\n",
        "Ú†ÛŒÚ©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŸ Ù…ÛŒØ§ÛŒ Ú©Ù„Ù…Ø§ØªØ´ Ø±Ùˆ Ù†Ú¯Ø§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ:\n",
        "\n",
        "Ø§Ú¯Ù‡ ØªÙˆØ´ Ú©Ù„Ù…Ù‡â€ŒÛŒ Â«Ø¨Ø±Ù†Ø¯Ù‡ Ø´Ø¯ÛŒÂ» Ù‡Ø³Øª â†’ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³Ù¾Ù… Ø²ÛŒØ§Ø¯ Ù…ÛŒØ´Ù‡.\n",
        "\n",
        "Ø§Ú¯Ù‡ ØªÙˆØ´ Ú©Ù„Ù…Ù‡â€ŒÛŒ Â«Ø®Ø±ÛŒØ¯Â» Ù‡Ø³Øª â†’ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³Ù¾Ù… Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡.\n",
        "\n",
        "Ø§Ú¯Ù‡ ØªÙˆØ´ Ú©Ù„Ù…Ù‡â€ŒÛŒ Â«Ø¯ÙˆØ³Øª Ø¹Ø²ÛŒØ²Â» Ù‡Ø³Øª â†’ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³Ù¾Ù… Ú©Ù…ØªØ± Ù…ÛŒØ´Ù‡.\n",
        "\n",
        "Ø­Ø§Ù„Ø§ Ù…ÛŒØ§ÛŒ Ø¨Ø§ Ù‚Ø§Ù†ÙˆÙ† Ø§Ø­ØªÙ…Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ:\n",
        "\n",
        "Ú†Ù‚Ø¯Ø± Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ø§Ø³Ù¾Ù… Ø¨Ø§Ø´Ù‡ØŒ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ú©Ù„Ù…Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø§Ø±Ù‡ØŸ\n",
        "Ú†Ù‚Ø¯Ø± Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ø§Ø³Ù¾Ù… Ù†Ø¨Ø§Ø´Ù‡ØŒ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù‡Ù…ÙˆÙ† Ú©Ù„Ù…Ø§ØªØŸ\n",
        "Ù‡Ø± Ú©Ø¯ÙˆÙ… Ø¨ÛŒØ´ØªØ± Ø¨ÙˆØ¯ â†’ Ù‡Ù…ÙˆÙ†Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.\n",
        "\n",
        "âœ¨ Ú†Ø±Ø§ Ø¨Ù‡Ø´ Ù…ÛŒÚ¯Ù† Naive (Ø³Ø§Ø¯Ù‡â€ŒÙ„ÙˆØ­Ø§Ù†Ù‡)ØŸ\n",
        "\n",
        "Ú†ÙˆÙ† ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ù‡Ù…Ù‡â€ŒÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ Ú©Ù„Ù…Ø§Øª) Ù…Ø³ØªÙ‚Ù„ Ø§Ø² Ù‡Ù… Ù‡Ø³ØªÙ†.\n",
        "Ø¯Ø± Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù‡Ù…ÛŒØ´Ù‡ Ø§ÛŒÙ†Ø·ÙˆØ± Ù†ÛŒØ³ØªØŒ ÙˆÙ„ÛŒ Ø§ÛŒÙ† ÙØ±Ø¶ Ø³Ø§Ø¯Ù‡ Ø¨Ø§Ø¹Ø« Ù…ÛŒØ´Ù‡ Ø®ÛŒÙ„ÛŒ Ø³Ø±ÛŒØ¹ Ùˆ Ø®ÙˆØ¨ Ú©Ø§Ø± Ú©Ù†Ù‡.\n",
        "\n",
        "âœ¨ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³\n",
        "Ù…Ø§ Ø¯Ø§Ø±ÛŒÙ… Ø§Ø­ØªÙ…Ø§Ù„ Ù…ÛŒâ€ŒØ³Ù†Ø¬ÛŒÙ….\n",
        "\n",
        "Ù…ÛŒâ€ŒÚ¯ÛŒÙ…: Â«Ø¨Ø§ Ø§ÛŒÙ† Ø´ÙˆØ§Ù‡Ø¯ØŒ Ú©Ø¯ÙˆÙ… Ø¯Ø³ØªÙ‡ Ù…Ø­ØªÙ…Ù„â€ŒØªØ±Ù‡ØŸÂ»\n",
        "\n",
        "Ø¨Ø¹Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø¨ÙˆØ¯Ù† Ø§Ø­ØªÙ…Ø§Ù„ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ….\n"
      ],
      "metadata": {
        "id": "hZrWzh0BrukD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB     # â† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Naive Bayes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª (Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡)\n",
        "# -----------------------------\n",
        "url = \"Dataset/diabetes.csv\"\n",
        "\n",
        "# ÙØ§ÛŒÙ„ diabetes.csv Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø®ÙˆØ¯ Ù‡Ø¯Ø± Ø¯Ø§Ø±Ø¯ â†’ Ù¾Ø³ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ names Ùˆ header Ù†ÛŒØ³Øª\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù„ÛŒØ¨Ù„\n",
        "# -----------------------------\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 4. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ ØªØ³ØªÛŒ\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ ÙˆÙ„ÛŒ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ NB)\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Naive Bayes\n",
        "# -----------------------------\n",
        "model = GaussianNB()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "#print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "#print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¨ÛŒÙ…Ø§Ø± Ø¬Ø¯ÛŒØ¯\n",
        "# -----------------------------\n",
        "new_patient = [[2, 120, 70, 25, 80, 30.5, 0.35, 35]]\n",
        "\n",
        "# Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ\n",
        "new_patient_scaled = scaler.transform(new_patient)\n",
        "\n",
        "prediction = model.predict(new_patient_scaled)[0]\n",
        "probabilities = model.predict_proba(new_patient_scaled)[0]\n",
        "\n",
        "print(\"\\nPrediction (0=Ø³Ø§Ù„Ù…, 1=Ø¯ÛŒØ§Ø¨ØªÛŒ):\", prediction)\n",
        "print(\"Probability of class 0:\", probabilities[0])\n",
        "print(\"Probability of class 1:\", probabilities[1])\n"
      ],
      "metadata": {
        "id": "NLWU9QYesTXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}