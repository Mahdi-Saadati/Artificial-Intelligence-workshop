{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOx52vngdYYAah7oHkjkfNt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Artificial-Intelligence-workshop/blob/main/5.a.%20Support%20Vector%20Machine%20(SVM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "âœ¨ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù† (SVM: Support Vector Machine) Ú†ÛŒØ³ØªØŸ\n",
        "\n",
        "ÙØ±Ø¶ Ú©Ù† Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¯Ùˆ Ú¯Ø±ÙˆÙ‡ Ø±Ùˆ Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ú©Ù†ÛŒ:\n",
        "\n",
        "âœ… Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ù‡Ø§ÛŒ Ù‚Ø¨ÙˆÙ„ Ø´Ø¯Ù‡ âœ…\n",
        "\n",
        "âŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ù‡Ø§ÛŒ Ø±Ø¯ Ø´Ø¯Ù‡ âŒ\n",
        "\n",
        "Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ø±ÙˆÛŒ ÛŒÚ© ØµÙØ­Ù‡ Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒ.\n",
        "Ø­Ø§Ù„Ø§ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ø®Ø· Ø¨Ú©Ø´ÛŒ Ú©Ù‡ Ø§ÛŒÙ† Ø¯Ùˆ Ú¯Ø±ÙˆÙ‡ Ø±Ùˆ Ø¬Ø¯Ø§ Ú©Ù†Ù‡.\n",
        "ÙˆÙ„ÛŒâ€¦\n",
        "\n",
        "ğŸ“Œ Ø¨ÛŒÙ† Ù‡Ù…Ù‡â€ŒÛŒ Ø®Ø·â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒØ´Ù‡ Ú©Ø´ÛŒØ¯ØŒ SVM Ø¯Ù†Ø¨Ø§Ù„ Ø¨Ù‡ØªØ±ÛŒÙ† Ø®Ø· Ù…Ù…Ú©Ù† Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ù‡!\n",
        "Ø¨Ù‡ØªØ±ÛŒÙ† Ø®Ø· ÛŒØ¹Ù†ÛŒ Ø®Ø·ÛŒ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ÙØ§ØµÙ„Ù‡ Ø±Ùˆ Ø§Ø² Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ú¯Ø±ÙˆÙ‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡.\n",
        "Ø¨Ù‡ Ø§ÙˆÙ† Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒÚ¯Ù† Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†.\n",
        "\n",
        "ğŸ” Ù¾Ø³ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡:\n",
        "\n",
        "âœ… SVM Ù…ÛŒØ§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ù†Ú¯Ø§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.\n",
        "\n",
        "âœ… ÛŒÚ© Ø®Ø· (ÛŒØ§ Ø¯Ø± Ø§Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„Ø§ØªØ±ØŒ ÛŒÚ© ØµÙØ­Ù‡) Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ú©Ù‡ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ Ø±Ùˆ Ø¬Ø¯Ø§ Ú©Ù†Ù‡.\n",
        "\n",
        "âœ… Ø§ÛŒÙ† Ø®Ø· Ø¬ÙˆØ±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´Ù‡ Ú©Ù‡ ÙØ§ØµÙ„Ù‡â€ŒØ§Ø´ Ø§Ø² Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†)\n",
        "Ø­Ø¯Ø§Ú©Ø«Ø± Ø¨Ø§Ø´Ù‡.\n",
        "\n",
        "âœ… Ø§ÛŒÙ†Ø·ÙˆØ±ÛŒ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ Ø¨Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ú¯Ù‡: Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ù…Ø§Ù„ Ú©Ø¯ÙˆÙ… Ø¯Ø³ØªÙ‡â€ŒØ³Øª.\n"
      ],
      "metadata": {
        "id": "hZrWzh0BrukD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC                     # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… SVM\n",
        "from sklearn.preprocessing import StandardScaler  # Ø¨Ø±Ø§ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª\n",
        "# -----------------------------\n",
        "url = \"Dataset/diabetes.csv\"\n",
        "columns = [\n",
        "    \"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
        "    \"Insulin\", \"BMI\", \"DiabetesPedigree\", \"Age\", \"Outcome\"\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, names=columns, header=0)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù„ÛŒØ¨Ù„\n",
        "# -----------------------------\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 4. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ ØªØ³ØªÛŒ\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ SVM)\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)   # Ø¢Ù…ÙˆØ²Ø´ + Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "X_test_scaled = scaler.transform(X_test)         # ÙÙ‚Ø· Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ SVM\n",
        "# -----------------------------\n",
        "model = SVC(\n",
        "    kernel='rbf',       # Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø±Ù†Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø³Ø§Ø¦Ù„ ÙˆØ§Ù‚Ø¹ÛŒ\n",
        "    probability=True,   # Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø­ØªÙ…Ø§Ù„\n",
        "    C=1.0,              # Ù¾Ø§Ø±Ø§Ù…ØªØ± Ú©Ù†ØªØ±Ù„ Ø®Ø·Ø§\n",
        "    gamma='scale',      # Ù†ÙˆØ¹ Ú¯Ø§Ù…Ø§\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨ÛŒÙ…Ø§Ø± Ø¬Ø¯ÛŒØ¯\n",
        "# -----------------------------\n",
        "new_patient = [[2, 120, 70, 25, 80, 30.5, 0.35, 35]]\n",
        "\n",
        "# Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø¬Ø¯ÛŒØ¯\n",
        "new_patient_scaled = scaler.transform(new_patient)\n",
        "\n",
        "prediction = model.predict(new_patient_scaled)[0]\n",
        "probabilities = model.predict_proba(new_patient_scaled)[0]\n",
        "\n",
        "print(\"\\nPrediction (0=Ø³Ø§Ù„Ù…, 1=Ø¯ÛŒØ§Ø¨ØªÛŒ):\", prediction)\n",
        "print(\"Probability of class 0:\", probabilities[0])\n",
        "print(\"Probability of class 1:\", probabilities[1])\n"
      ],
      "metadata": {
        "id": "NLWU9QYesTXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}