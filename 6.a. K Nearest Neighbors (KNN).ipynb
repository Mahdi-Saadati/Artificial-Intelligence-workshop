{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFe0bs8xUHPAaIghg4Yv0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahdi-Saadati/Artificial-Intelligence-workshop/blob/main/6.a.%20K%20Nearest%20Neighbors%20(KNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" align=\"right\">\n",
        "\n",
        "\n",
        "ğŸ“Œ K Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡ (KNN: K Nearest Neighbors) ÛŒØ¹Ù†ÛŒ Ú†ÛŒØŸ\n",
        "\n",
        "ÙØ±Ø¶ Ú©Ù† Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒ Ø¨ÙÙ‡Ù…ÛŒ ÛŒÚ© Ù…ÛŒÙˆÙ‡â€ŒÛŒ Ø¬Ø¯ÛŒØ¯ ğŸ Ú†Ù‡ Ù…ÛŒÙˆÙ‡â€ŒØ§ÛŒ Ø§Ø³Øª.\n",
        "\n",
        "Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒ ÙØ±Ù…ÙˆÙ„ Ø³Ø®ØªÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØŒ ÙÙ‚Ø· Ù†Ú¯Ø§Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ Ø§Ø·Ø±Ø§ÙØ´ Ú†Ù‡ Ù…ÛŒÙˆÙ‡â€ŒÙ‡Ø§ÛŒÛŒ Ù‡Ø³ØªÙ†!\n",
        "\n",
        "âœ… Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø³Ø§Ø¯Ù‡:\n",
        "\n",
        "KNN Ù…ÛŒâ€ŒÚ¯Ù‡: \"Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ ÛŒÚ© ÙØ±Ù…ÙˆÙ„ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ù…ØŒ Ù…ÛŒØ±Ù… Ø³Ø±Ø§Øº Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ù… Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ø¬Ø¯ÛŒØ¯ Ø´Ø¨ÛŒÙ‡ Ú©Ø¯ÙˆÙ…â€ŒÙ‡Ø§Ø³Øª.\"\n",
        "\n",
        "Ù…Ø«Ù„Ø§Ù‹:\n",
        "\n",
        "Ø§Ú¯Ø± Ø§Ø·Ø±Ø§Ù Ø§ÛŒÙ† Ù…ÛŒÙˆÙ‡ Ø¨ÛŒØ´ØªØ± Ø³ÛŒØ¨ ğŸ Ø¨Ø§Ø´Ù† â†’ Ù¾Ø³ Ø§ÛŒÙ† Ù‡Ù… Ø³ÛŒØ¨Ù‡!\n",
        "\n",
        "Ø§Ú¯Ø± Ø§Ø·Ø±Ø§ÙØ´ Ø¨ÛŒØ´ØªØ± Ù¾Ø±ØªÙ‚Ø§Ù„ ğŸŠ Ø¨Ø§Ø´Ù† â†’ Ù¾Ø³ Ø§ÛŒÙ† Ù¾Ø±ØªÙ‚Ø§Ù„Ù‡!\n",
        "\n",
        "âœ… Ø­Ø±Ù K ÛŒØ¹Ù†ÛŒ:\n",
        "\n",
        "Ú†Ù†Ø¯ ØªØ§ Ù‡Ù…Ø³Ø§ÛŒÙ‡ Ø±Ùˆ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±Ù…ØŸ\n",
        "Ù…Ø«Ù„Ø§Ù‹ K=3 ÛŒØ¹Ù†ÛŒ: Û³ ØªØ§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡ Ø±Ùˆ Ù†Ú¯Ø§Ù‡ Ú©Ù†.\n",
        "\n",
        "âœ¨ Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡:\n",
        "Ù…Ø¯Ù„ Ø®Ø§ØµÛŒ ÛŒØ§Ø¯ Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡.\n",
        "\n",
        "ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.\n",
        "\n",
        "ÙˆÙ‚ØªÛŒ ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ù…ÛŒØ§Ø¯ â†’ Ù…ÛŒØ±Ù‡ K ØªØ§ Ø§Ø² Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø±Ùˆ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ â†’ Ø±Ø£ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.\n",
        "\n",
        "âœ… ÛŒÚ© Ù…Ø«Ø§Ù„ Ø¨Ø§Ù…Ø²Ù‡ Ø¨Ø§ Ù¾Ø§ÛŒØªÙˆÙ†\n",
        "\n",
        "Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ø§ Ù…ÛŒÙˆÙ‡â€ŒÙ‡Ø§ Ú©Ø§Ø± Ú©Ù†ÛŒÙ… ğŸğŸŠ:"
      ],
      "metadata": {
        "id": "hZrWzh0BrukD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier   # â† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… KNN\n",
        "from sklearn.preprocessing import StandardScaler      # â† Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ KNN\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª (Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡)\n",
        "# -----------------------------\n",
        "url = \"Dataset/diabetes.csv\"\n",
        "\n",
        "# ÙØ§ÛŒÙ„ diabetes.csv Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø®ÙˆØ¯Ø´ Ù‡ÙØ¯Ø± Ø¯Ø§Ø±Ø¯ â†’ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ names Ù†ÛŒØ³Øª\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù„ÛŒØ¨Ù„\n",
        "# -----------------------------\n",
        "X = df.drop(\"Outcome\", axis=1)\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 4. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ ØªØ³ØªÛŒ\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ KNN)\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ KNN\n",
        "# -----------------------------\n",
        "model = KNeighborsClassifier(n_neighbors=5)   # k=5 Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "#print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "#print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¨ÛŒÙ…Ø§Ø± Ø¬Ø¯ÛŒØ¯\n",
        "# -----------------------------\n",
        "new_patient = [[2, 120, 70, 25, 80, 30.5, 0.35, 35]]\n",
        "\n",
        "# Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ\n",
        "new_patient_scaled = scaler.transform(new_patient)\n",
        "\n",
        "prediction = model.predict(new_patient_scaled)[0]\n",
        "probabilities = model.predict_proba(new_patient_scaled)[0]\n",
        "\n",
        "print(\"\\nPrediction (0=Ø³Ø§Ù„Ù…, 1=Ø¯ÛŒØ§Ø¨ØªÛŒ):\", prediction)\n",
        "print(\"Probability of class 0:\", probabilities[0])\n",
        "print(\"Probability of class 1:\", probabilities[1])\n"
      ],
      "metadata": {
        "id": "NLWU9QYesTXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}